{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2693fd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os, io, random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dropout, Activation, Add, Multiply, ReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.losses import BinaryFocalCrossentropy\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab78a928",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH = 16\n",
    "RESIZE = 128\n",
    "EPS = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f843ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(y_true, y_pred, smooth=1e-6):\n",
    "    \"\"\"\n",
    "    Batch-wise Dice coefficient: returns mean Dice across the batch.\n",
    "    y_true, y_pred: tensors shaped [B, H, W, C] (C usually 1).\n",
    "    \"\"\"\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    # Sum over spatial dims per sample\n",
    "    axes = tf.range(1, tf.rank(y_pred))  # [H,W,C]\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=axes)\n",
    "    sums = tf.reduce_sum(y_true, axis=axes) + tf.reduce_sum(y_pred, axis=axes)\n",
    "    dice = (2.0 * intersection + smooth) / (sums + smooth)\n",
    "    # dice shape: [B, C] -> average over channels then batch\n",
    "    dice = tf.reduce_mean(dice, axis=-1)\n",
    "    return tf.reduce_mean(dice)\n",
    "\n",
    "\n",
    "class CombinedSegmentationLoss(tf.keras.losses.Loss):\n",
    "    \"\"\"\n",
    "    Combined loss:\n",
    "      total_loss = w_dice * (1 - Dice)\n",
    "                 + w_ft   * FocalTversky\n",
    "                 + w_edge * EdgeLoss\n",
    "\n",
    "    Implemented in a batch-vectorized and numerically stable way.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        alpha=0.7,        # Tversky alpha (FP weight)\n",
    "        beta=0.3,         # Tversky beta (FN weight)  --> increase beta to penalize FN more\n",
    "        ft_gamma=0.75,    # Focal Tversky focusing factor\n",
    "        focal_alpha=0.95, # Internal Focal BCE (optional)\n",
    "        focal_gamma=1.5,\n",
    "        w_dice=0.6,\n",
    "        w_ft=0.3,\n",
    "        w_edge=0.1,\n",
    "        from_logits=False,\n",
    "        name=\"combined_segmentation_loss\",\n",
    "    ):\n",
    "        super().__init__(name=name)\n",
    "        # Tversky / Focal Tversky params\n",
    "        self.alpha = float(alpha)\n",
    "        self.beta = float(beta)\n",
    "        self.ft_gamma = float(ft_gamma)\n",
    "        # optional focal BCE (not used in final sum by default; kept if you want)\n",
    "        self.focal_bce = BinaryFocalCrossentropy(alpha=focal_alpha, gamma=focal_gamma, from_logits=from_logits)\n",
    "        # weights\n",
    "        self.w_dice = float(w_dice)\n",
    "        self.w_ft = float(w_ft)\n",
    "        self.w_edge = float(w_edge)\n",
    "        self.from_logits = from_logits\n",
    "\n",
    "    def _prepare_predictions(self, y_pred):\n",
    "        \"\"\"If logits provided, convert to probabilities.\"\"\"\n",
    "        if self.from_logits:\n",
    "            y_pred = tf.nn.sigmoid(y_pred)\n",
    "        # ensure float32\n",
    "        return tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        y_true, y_pred: tensors [B, H, W, C] (C=1 typically)\n",
    "        returns scalar loss (mean over batch).\n",
    "        \"\"\"\n",
    "        y_pred = self._prepare_predictions(y_pred)\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "\n",
    "        # ---- Dice Loss (batch-wise, stable) ----\n",
    "        axes = tf.range(1, tf.rank(y_pred))  # spatial + channel dims\n",
    "        intersection = tf.reduce_sum(y_true * y_pred, axis=axes)    # shape [B, C]\n",
    "        sum_ytrue = tf.reduce_sum(y_true, axis=axes)\n",
    "        sum_ypred = tf.reduce_sum(y_pred, axis=axes)\n",
    "        dice_score = (2.0 * intersection + EPS) / (sum_ytrue + sum_ypred + EPS)  # [B, C]\n",
    "        dice_score = tf.reduce_mean(dice_score, axis=-1)  # per-sample (avg over channels)\n",
    "        dice_loss = 1.0 - dice_score                       # [B]\n",
    "\n",
    "        # ---- Focal Tversky Loss (batch-wise) ----\n",
    "        # compute TP, FP, FN per sample and channel\n",
    "        TP = intersection\n",
    "        FP = tf.reduce_sum((1.0 - y_true) * y_pred, axis=axes)\n",
    "        FN = tf.reduce_sum(y_true * (1.0 - y_pred), axis=axes)\n",
    "\n",
    "        # Tversky per sample/channel\n",
    "        tversky = (TP + EPS) / (TP + self.alpha * FP + self.beta * FN + EPS)  # [B, C]\n",
    "        tversky = tf.reduce_mean(tversky, axis=-1)  # [B]\n",
    "        focal_tversky = tf.pow((1.0 - tversky), self.ft_gamma)  # [B]\n",
    "\n",
    "        # ---- Edge loss (gradient-based) ----\n",
    "        # tf.image.sobel_edges returns shape [B, H, W, C, 2]\n",
    "        # compute gradient magnitude per-pixel and per-channel\n",
    "        sobel_pred = tf.image.sobel_edges(y_pred)   # [B,H,W,C,2]\n",
    "        sobel_true = tf.image.sobel_edges(y_true)\n",
    "        # compute magnitude: sqrt(dx^2 + dy^2)\n",
    "        # sobel[...,0] is dy, sobel[...,1] is dx (both shape [B,H,W,C])\n",
    "        mag_pred = tf.sqrt(tf.square(sobel_pred[..., 0]) + tf.square(sobel_pred[..., 1]) + EPS)\n",
    "        mag_true = tf.sqrt(tf.square(sobel_true[..., 0]) + tf.square(sobel_true[..., 1]) + EPS)\n",
    "        # absolute difference and mean per sample\n",
    "        edge_diff = tf.abs(mag_true - mag_pred)   # [B,H,W,C]\n",
    "        edge_loss_per_sample = tf.reduce_mean(edge_diff, axis=axes)  # [B]\n",
    "        # edge_loss_per_sample is mean difference across H,W,C\n",
    "\n",
    "        # ---- combine losses per sample and then average ----\n",
    "        total_per_sample = (\n",
    "            self.w_dice * dice_loss\n",
    "            + self.w_ft * focal_tversky\n",
    "            + self.w_edge * edge_loss_per_sample\n",
    "        )\n",
    "\n",
    "        # final scalar\n",
    "        return tf.reduce_mean(total_per_sample)\n",
    "\n",
    "    def get_config(self):\n",
    "        cfg = super().get_config()\n",
    "        cfg.update({\n",
    "            \"alpha\": self.alpha,\n",
    "            \"beta\": self.beta,\n",
    "            \"ft_gamma\": self.ft_gamma,\n",
    "            \"w_dice\": self.w_dice,\n",
    "            \"w_ft\": self.w_ft,\n",
    "            \"w_edge\": self.w_edge,\n",
    "            \"from_logits\": self.from_logits,\n",
    "        })\n",
    "        return cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19e6c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def focal_tversky_loss(y_true, y_pred, alpha=0.7, beta=0.3, gamma=0.75):\n",
    "#     y_true_f = K.flatten(y_true)\n",
    "#     y_pred_f = K.flatten(y_pred)\n",
    "    \n",
    "#     TP = K.sum(y_true_f * y_pred_f)\n",
    "#     FP = K.sum((1 - y_true_f) * y_pred_f)\n",
    "#     FN = K.sum(y_true_f * (1 - y_pred_f))\n",
    "    \n",
    "#     tversky = (TP + 1e-6) / (TP + alpha * FP + beta * FN + 1e-6)\n",
    "#     return K.pow((1 - tversky), gamma)\n",
    "\n",
    "\n",
    "# def dice_coefficient(y_true, y_pred, smooth=1e-6):\n",
    "#     y_true_f = tf.cast(tf.reshape(y_true, [-1]), tf.float32)\n",
    "#     y_pred_f = tf.cast(tf.reshape(y_pred, [-1]), tf.float32)\n",
    "#     y_pred_f = tf.clip_by_value(y_pred_f, smooth, 1)\n",
    "#     y_true_f = tf.clip_by_value(y_true_f, smooth, 1)\n",
    "#     intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "#     return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "# Combined Dice + Focal Loss\n",
    "# class DiceFocalLoss(tf.keras.losses.Loss):\n",
    "#     def __init__(self, alpha=0.95, gamma=1.5):\n",
    "#         super().__init__()\n",
    "#         self.focal = BinaryFocalCrossentropy(alpha=alpha, gamma=gamma)\n",
    "\n",
    "#     def call(self, y_true, y_pred):\n",
    "#         y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n",
    "#         dice_loss = 1 - dice_coefficient(y_true, y_pred)\n",
    "#         focal_loss = self.focal(y_true, y_pred)\n",
    "#         return dice_loss + 0.01 * focal_loss\n",
    "\n",
    "\n",
    "# def combined_loss(y_true, y_pred):\n",
    "#     return 0.7 * dice_loss(y_true, y_pred) + 0.3 * focal_tversky_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "# def edge_loss(y_true, y_pred):\n",
    "#     sobel_x = tf.image.sobel_edges(y_pred)[..., 0]\n",
    "#     sobel_y = tf.image.sobel_edges(y_pred)[..., 1]\n",
    "#     edges_pred = tf.sqrt(tf.square(sobel_x) + tf.square(sobel_y))\n",
    "\n",
    "#     sobel_x_t = tf.image.sobel_edges(y_true)[..., 0]\n",
    "#     sobel_y_t = tf.image.sobel_edges(y_true)[..., 1]\n",
    "#     edges_true = tf.sqrt(tf.square(sobel_x_t) + tf.square(sobel_y_t))\n",
    "    \n",
    "#     return tf.reduce_mean(tf.abs(edges_true - edges_pred))\n",
    "\n",
    "\n",
    "# def total_loss(y_true, y_pred):\n",
    "#     return 0.6 * combined_loss(y_true, y_pred) + 0.4 * edge_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4194c286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tif_data(data_dir):\n",
    "    images, masks = [], []\n",
    "    for patient_dir in os.listdir(data_dir):\n",
    "        patient_path = os.path.join(data_dir, patient_dir)\n",
    "        if not os.path.isdir(patient_path):\n",
    "            continue\n",
    "        # Get all .tif files in the patient directory\n",
    "        tif_files = [f for f in os.listdir(patient_path) if f.endswith('.tif') and 'mask' not in f]\n",
    "        for img_file in tif_files:\n",
    "            img_path = os.path.join(patient_path, img_file)\n",
    "            images.append(img_path)\n",
    "            # Construct corresponding mask filename\n",
    "            mask_file = img_file.replace('.tif', '_mask.tif')\n",
    "            mask_path = os.path.join(patient_path, mask_file)\n",
    "            masks.append(mask_path)\n",
    "            if not os.path.exists(mask_path):\n",
    "                continue  # Skip if mask file doesn’t exist\n",
    "    \n",
    "    return pd.DataFrame({'img': images, 'mask': masks})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af7afe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_addrs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5346b35e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "img",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mask",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "d6095a81-8958-4a68-be0b-4543d8be340d",
       "rows": [
        [
         "0",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_1.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_1_mask.tif"
        ],
        [
         "1",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_10.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_10_mask.tif"
        ],
        [
         "2",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_11.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_11_mask.tif"
        ],
        [
         "3",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_12.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_12_mask.tif"
        ],
        [
         "4",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_13.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_13_mask.tif"
        ],
        [
         "5",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_14.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_14_mask.tif"
        ],
        [
         "6",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_15.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_15_mask.tif"
        ],
        [
         "7",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_16.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_16_mask.tif"
        ],
        [
         "8",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_17.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_17_mask.tif"
        ],
        [
         "9",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_18.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_18_mask.tif"
        ],
        [
         "10",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_19.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_19_mask.tif"
        ],
        [
         "11",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_2.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_2_mask.tif"
        ],
        [
         "12",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_20.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_20_mask.tif"
        ],
        [
         "13",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_21.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_21_mask.tif"
        ],
        [
         "14",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_22.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_22_mask.tif"
        ],
        [
         "15",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_23.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_23_mask.tif"
        ],
        [
         "16",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_3.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_3_mask.tif"
        ],
        [
         "17",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_4.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_4_mask.tif"
        ],
        [
         "18",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_5.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_5_mask.tif"
        ],
        [
         "19",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_6.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_6_mask.tif"
        ],
        [
         "20",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_7.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_7_mask.tif"
        ],
        [
         "21",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_8.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_8_mask.tif"
        ],
        [
         "22",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_9.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_9_mask.tif"
        ],
        [
         "23",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_1.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_1_mask.tif"
        ],
        [
         "24",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_10.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_10_mask.tif"
        ],
        [
         "25",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_11.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_11_mask.tif"
        ],
        [
         "26",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_12.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_12_mask.tif"
        ],
        [
         "27",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_13.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_13_mask.tif"
        ],
        [
         "28",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_14.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_14_mask.tif"
        ],
        [
         "29",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_15.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_15_mask.tif"
        ],
        [
         "30",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_16.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_16_mask.tif"
        ],
        [
         "31",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_17.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_17_mask.tif"
        ],
        [
         "32",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_18.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_18_mask.tif"
        ],
        [
         "33",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_19.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_19_mask.tif"
        ],
        [
         "34",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_2.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_2_mask.tif"
        ],
        [
         "35",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_20.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_20_mask.tif"
        ],
        [
         "36",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_3.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_3_mask.tif"
        ],
        [
         "37",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_4.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_4_mask.tif"
        ],
        [
         "38",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_5.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_5_mask.tif"
        ],
        [
         "39",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_6.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_6_mask.tif"
        ],
        [
         "40",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_7.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_7_mask.tif"
        ],
        [
         "41",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_8.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_8_mask.tif"
        ],
        [
         "42",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_9.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4942_19970222\\TCGA_CS_4942_19970222_9_mask.tif"
        ],
        [
         "43",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4943_20000902\\TCGA_CS_4943_20000902_1.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4943_20000902\\TCGA_CS_4943_20000902_1_mask.tif"
        ],
        [
         "44",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4943_20000902\\TCGA_CS_4943_20000902_10.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4943_20000902\\TCGA_CS_4943_20000902_10_mask.tif"
        ],
        [
         "45",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4943_20000902\\TCGA_CS_4943_20000902_11.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4943_20000902\\TCGA_CS_4943_20000902_11_mask.tif"
        ],
        [
         "46",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4943_20000902\\TCGA_CS_4943_20000902_12.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4943_20000902\\TCGA_CS_4943_20000902_12_mask.tif"
        ],
        [
         "47",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4943_20000902\\TCGA_CS_4943_20000902_13.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4943_20000902\\TCGA_CS_4943_20000902_13_mask.tif"
        ],
        [
         "48",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4943_20000902\\TCGA_CS_4943_20000902_14.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4943_20000902\\TCGA_CS_4943_20000902_14_mask.tif"
        ],
        [
         "49",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4943_20000902\\TCGA_CS_4943_20000902_15.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4943_20000902\\TCGA_CS_4943_20000902_15_mask.tif"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 3929
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:/Github/Brain Tumor MRI Segmentation/dataset...</td>\n",
       "      <td>D:/Github/Brain Tumor MRI Segmentation/dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:/Github/Brain Tumor MRI Segmentation/dataset...</td>\n",
       "      <td>D:/Github/Brain Tumor MRI Segmentation/dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:/Github/Brain Tumor MRI Segmentation/dataset...</td>\n",
       "      <td>D:/Github/Brain Tumor MRI Segmentation/dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:/Github/Brain Tumor MRI Segmentation/dataset...</td>\n",
       "      <td>D:/Github/Brain Tumor MRI Segmentation/dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:/Github/Brain Tumor MRI Segmentation/dataset...</td>\n",
       "      <td>D:/Github/Brain Tumor MRI Segmentation/dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3924</th>\n",
       "      <td>D:/Github/Brain Tumor MRI Segmentation/dataset...</td>\n",
       "      <td>D:/Github/Brain Tumor MRI Segmentation/dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3925</th>\n",
       "      <td>D:/Github/Brain Tumor MRI Segmentation/dataset...</td>\n",
       "      <td>D:/Github/Brain Tumor MRI Segmentation/dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3926</th>\n",
       "      <td>D:/Github/Brain Tumor MRI Segmentation/dataset...</td>\n",
       "      <td>D:/Github/Brain Tumor MRI Segmentation/dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3927</th>\n",
       "      <td>D:/Github/Brain Tumor MRI Segmentation/dataset...</td>\n",
       "      <td>D:/Github/Brain Tumor MRI Segmentation/dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3928</th>\n",
       "      <td>D:/Github/Brain Tumor MRI Segmentation/dataset...</td>\n",
       "      <td>D:/Github/Brain Tumor MRI Segmentation/dataset...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3929 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    img  \\\n",
       "0     D:/Github/Brain Tumor MRI Segmentation/dataset...   \n",
       "1     D:/Github/Brain Tumor MRI Segmentation/dataset...   \n",
       "2     D:/Github/Brain Tumor MRI Segmentation/dataset...   \n",
       "3     D:/Github/Brain Tumor MRI Segmentation/dataset...   \n",
       "4     D:/Github/Brain Tumor MRI Segmentation/dataset...   \n",
       "...                                                 ...   \n",
       "3924  D:/Github/Brain Tumor MRI Segmentation/dataset...   \n",
       "3925  D:/Github/Brain Tumor MRI Segmentation/dataset...   \n",
       "3926  D:/Github/Brain Tumor MRI Segmentation/dataset...   \n",
       "3927  D:/Github/Brain Tumor MRI Segmentation/dataset...   \n",
       "3928  D:/Github/Brain Tumor MRI Segmentation/dataset...   \n",
       "\n",
       "                                                   mask  \n",
       "0     D:/Github/Brain Tumor MRI Segmentation/dataset...  \n",
       "1     D:/Github/Brain Tumor MRI Segmentation/dataset...  \n",
       "2     D:/Github/Brain Tumor MRI Segmentation/dataset...  \n",
       "3     D:/Github/Brain Tumor MRI Segmentation/dataset...  \n",
       "4     D:/Github/Brain Tumor MRI Segmentation/dataset...  \n",
       "...                                                 ...  \n",
       "3924  D:/Github/Brain Tumor MRI Segmentation/dataset...  \n",
       "3925  D:/Github/Brain Tumor MRI Segmentation/dataset...  \n",
       "3926  D:/Github/Brain Tumor MRI Segmentation/dataset...  \n",
       "3927  D:/Github/Brain Tumor MRI Segmentation/dataset...  \n",
       "3928  D:/Github/Brain Tumor MRI Segmentation/dataset...  \n",
       "\n",
       "[3929 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5d9e6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl = []\n",
    "\n",
    "for each in df['mask'].tolist():\n",
    "    im = Image.open(each)\n",
    "    imarray = np.array(im)\n",
    "    if np.sum(imarray) == 0:\n",
    "        lbl.append(0)\n",
    "    else:\n",
    "        lbl.append(1)\n",
    "\n",
    "df['label'] = pd.Series(lbl)\n",
    "dff = df[df['label'] == 1].copy(deep=True)\n",
    "dff.drop(['label'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad9b8b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "img",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mask",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "e4bcd406-a40f-4446-b06a-fac6f471803d",
       "rows": [
        [
         "0",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_11.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_11_mask.tif"
        ],
        [
         "1",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_12.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_12_mask.tif"
        ],
        [
         "2",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_13.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_13_mask.tif"
        ],
        [
         "3",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_14.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_14_mask.tif"
        ],
        [
         "4",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_15.tif",
         "D:/Github/Brain Tumor MRI Segmentation/dataset/TCGA_CS_4941_19960909\\TCGA_CS_4941_19960909_15_mask.tif"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:/Github/Brain Tumor MRI Segmentation/dataset...</td>\n",
       "      <td>D:/Github/Brain Tumor MRI Segmentation/dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:/Github/Brain Tumor MRI Segmentation/dataset...</td>\n",
       "      <td>D:/Github/Brain Tumor MRI Segmentation/dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:/Github/Brain Tumor MRI Segmentation/dataset...</td>\n",
       "      <td>D:/Github/Brain Tumor MRI Segmentation/dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:/Github/Brain Tumor MRI Segmentation/dataset...</td>\n",
       "      <td>D:/Github/Brain Tumor MRI Segmentation/dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:/Github/Brain Tumor MRI Segmentation/dataset...</td>\n",
       "      <td>D:/Github/Brain Tumor MRI Segmentation/dataset...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 img  \\\n",
       "0  D:/Github/Brain Tumor MRI Segmentation/dataset...   \n",
       "1  D:/Github/Brain Tumor MRI Segmentation/dataset...   \n",
       "2  D:/Github/Brain Tumor MRI Segmentation/dataset...   \n",
       "3  D:/Github/Brain Tumor MRI Segmentation/dataset...   \n",
       "4  D:/Github/Brain Tumor MRI Segmentation/dataset...   \n",
       "\n",
       "                                                mask  \n",
       "0  D:/Github/Brain Tumor MRI Segmentation/dataset...  \n",
       "1  D:/Github/Brain Tumor MRI Segmentation/dataset...  \n",
       "2  D:/Github/Brain Tumor MRI Segmentation/dataset...  \n",
       "3  D:/Github/Brain Tumor MRI Segmentation/dataset...  \n",
       "4  D:/Github/Brain Tumor MRI Segmentation/dataset...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff.reset_index(drop=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "447517a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c81997a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 58\n",
    "# masks = dff['mask'].tolist()\n",
    "# images = dff['img'].tolist()\n",
    "# mask = masks[idx]\n",
    "# image = images[idx]\n",
    "# maskg = Image.open(mask)\n",
    "# mask = np.array(maskg)\n",
    "# # plt.imshow(maskg)\n",
    "# imageg = Image.open(image)\n",
    "# image = np.array(imageg)\n",
    "# # plt.imshow(imageg)\n",
    "\n",
    "# fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "# ax[0].imshow(maskg, cmap='gray')\n",
    "# ax[0].set_title(\"Mask\")\n",
    "\n",
    "# ax[1].imshow(imageg, cmap='gray')\n",
    "# ax[1].set_title(\"Image\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eddf5f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, mask):\n",
    "    return random_crop_with_zoomout(image, mask, target_size=(RESIZE, RESIZE), p=0.3)\n",
    "\n",
    "\n",
    "def random_crop_with_zoomout(image, mask, target_size=(RESIZE, RESIZE), p=0.5):\n",
    "    \"\"\"\n",
    "    Apply crop+zoomout augmentation randomly with probability p.\n",
    "    \"\"\"\n",
    "    # Generate random number\n",
    "    do_augment = tf.random.uniform([], 0, 1.0) < p\n",
    "\n",
    "    def augmented():\n",
    "        return mask_aware_crop(image, mask, target_size)\n",
    "\n",
    "    def identity():\n",
    "        # Just resize without augmentation\n",
    "        image_resized = tf.image.resize(image, target_size, method='bilinear')\n",
    "        mask_resized = tf.image.resize(mask, target_size, method='nearest')\n",
    "        return image_resized, mask_resized\n",
    "\n",
    "    return tf.cond(do_augment, augmented, identity)\n",
    "\n",
    "\n",
    "def mask_aware_crop(image, mask, target_size=(RESIZE, RESIZE)):\n",
    "    # mask = tf.cast(mask, tf.int32)\n",
    "    row, col = tf.shape(mask)[0], tf.shape(mask)[1]\n",
    "\n",
    "    # Find nonzero indices (True positions)\n",
    "    non_zero = tf.where(mask > 0)\n",
    "\n",
    "    # Get bounding box coordinates\n",
    "    r_min = tf.reduce_min(non_zero[:, 1])\n",
    "    r_max = tf.reduce_max(non_zero[:, 1])\n",
    "    c_min = tf.reduce_min(non_zero[:, 0])\n",
    "    c_max = tf.reduce_max(non_zero[:, 0])\n",
    "\n",
    "    # Compute distances to borders\n",
    "    rmindist = tf.cast(r_min, tf.int32)\n",
    "    cmindist = tf.cast(c_min, tf.int32)\n",
    "    rmaxdist = tf.cast(col, tf.int32) - tf.cast(r_max, tf.int32)\n",
    "    cmaxdist = tf.cast(row, tf.int32) - tf.cast(c_max, tf.int32)\n",
    "\n",
    "    zoomout = tf.minimum(tf.minimum(rmindist, rmaxdist),\n",
    "                        tf.minimum(cmindist, cmaxdist))\n",
    "\n",
    "    zoomout_factor = tf.where(zoomout > 50, 0.3, 0.8)\n",
    "    zoomout = tf.cast(tf.cast(zoomout, tf.float32) * zoomout_factor, tf.int32)\n",
    "\n",
    "    # Expanded box coordinates (clamped to image size)\n",
    "    rmin = tf.cast(tf.maximum(tf.cast(r_min, tf.int64) - tf.cast(zoomout, tf.int64), 0), tf.int32)\n",
    "    cmin = tf.cast(tf.maximum(tf.cast(c_min, tf.int64) - tf.cast(zoomout, tf.int64), 0), tf.int32)\n",
    "    rmax = tf.cast(tf.minimum(tf.cast(r_max, tf.int64) + tf.cast(zoomout, tf.int64), tf.cast(col, tf.int64)), tf.int32)\n",
    "    cmax = tf.cast(tf.minimum(tf.cast(c_max, tf.int64) + tf.cast(zoomout, tf.int64), tf.cast(row, tf.int64)), tf.int32)\n",
    "\n",
    "    # Crop image and mask\n",
    "    cropped_mask = mask[cmin:cmax, rmin:rmax]\n",
    "    cropped_img = image[cmin:cmax, rmin:rmax]\n",
    "\n",
    "    resized_img = tf.image.resize(cropped_img, target_size, method='bilinear')\n",
    "    # cropped_mask = tf.expand_dims(cropped_mask, axis=-1)\n",
    "    resized_mask = tf.image.resize(cropped_mask, target_size, method='nearest')\n",
    "    # resized_mask = tf.squeeze(resized_mask, axis=-1)\n",
    "    \n",
    "    return resized_img, resized_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba8ab31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 961, Val: 206, Test: 206\n"
     ]
    }
   ],
   "source": [
    "x_tr, x_val = train_test_split(dff, test_size=0.3, random_state=42)\n",
    "x_val, x_ts = train_test_split(x_val, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Train: {len(x_tr)}, Val: {len(x_val)}, Test: {len(x_ts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cff74a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_tif_image(path, ch):\n",
    "    img = Image.open(path.decode())\n",
    "    \n",
    "    if int(ch) == 3:\n",
    "        img = img.convert('RGB')\n",
    "    else:\n",
    "        img = img.convert('L')\n",
    "    \n",
    "    img = img.resize((RESIZE, RESIZE))\n",
    "    img = np.array(img).astype(np.float32) / 255.0\n",
    "\n",
    "    # If grayscale (2D), expand to [H, W, 1]\n",
    "    if img.ndim == 2:\n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "\n",
    "def load_image_and_mask(image_path, mask_path):\n",
    "    # Load image\n",
    "    image = tf.numpy_function(_load_tif_image, [image_path, 3], tf.float32)\n",
    "    image.set_shape([RESIZE, RESIZE, 3])  # or [RESIZE, RESIZE, 1]\n",
    "\n",
    "    # Load mask (assume single channel)\n",
    "    mask = tf.numpy_function(_load_tif_image, [mask_path, 1], tf.float32)\n",
    "    mask.set_shape([RESIZE, RESIZE, 1])\n",
    "\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6d0afac",
   "metadata": {},
   "outputs": [],
   "source": [
    "trds = tf.data.Dataset.from_tensor_slices((x_tr['img'], x_tr['mask']))\n",
    "vlds = tf.data.Dataset.from_tensor_slices((x_val['img'], x_val['mask']))\n",
    "tsds = tf.data.Dataset.from_tensor_slices((x_ts['img'], x_ts['mask']))\n",
    "\n",
    "\n",
    "trds = (trds\n",
    "\t.shuffle(1024)\n",
    "\t.map(load_image_and_mask, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\t.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\t.cache()\n",
    "\t.batch(BATCH)\n",
    "\t.prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "vlds = (vlds\n",
    "\t.shuffle(1024)\n",
    "\t.map(load_image_and_mask, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\t.cache()\n",
    "\t.batch(BATCH)\n",
    "\t.prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "tsds = (tsds\n",
    "\t.shuffle(1024)\n",
    "\t.map(load_image_and_mask, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\t.cache()\n",
    "\t.batch(BATCH)\n",
    "\t.prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9543443b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0.23921569 0.         0.        ]\n",
      "   [0.23921569 0.00392157 0.        ]\n",
      "   [0.23921569 0.00784314 0.        ]\n",
      "   ...\n",
      "   [0.23921569 0.00784314 0.        ]\n",
      "   [0.23921569 0.00392157 0.        ]\n",
      "   [0.23921569 0.         0.        ]]\n",
      "\n",
      "  [[0.23921569 0.00392157 0.        ]\n",
      "   [0.23921569 0.00784314 0.        ]\n",
      "   [0.23921569 0.00784314 0.        ]\n",
      "   ...\n",
      "   [0.23529412 0.00784314 0.        ]\n",
      "   [0.23921569 0.00392157 0.        ]\n",
      "   [0.23921569 0.00392157 0.        ]]\n",
      "\n",
      "  [[0.23921569 0.00392157 0.        ]\n",
      "   [0.23921569 0.00784314 0.        ]\n",
      "   [0.23921569 0.00784314 0.        ]\n",
      "   ...\n",
      "   [0.23529412 0.00392157 0.        ]\n",
      "   [0.23921569 0.00392157 0.        ]\n",
      "   [0.23921569 0.00392157 0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.23921569 0.         0.        ]\n",
      "   [0.23921569 0.         0.        ]\n",
      "   [0.23529412 0.00392157 0.        ]\n",
      "   ...\n",
      "   [0.23921569 0.00784314 0.        ]\n",
      "   [0.23921569 0.00392157 0.        ]\n",
      "   [0.23921569 0.         0.        ]]\n",
      "\n",
      "  [[0.23921569 0.         0.        ]\n",
      "   [0.23921569 0.00392157 0.        ]\n",
      "   [0.23921569 0.00392157 0.00392157]\n",
      "   ...\n",
      "   [0.23529412 0.00784314 0.        ]\n",
      "   [0.23921569 0.00392157 0.        ]\n",
      "   [0.23921569 0.         0.        ]]\n",
      "\n",
      "  [[0.23921569 0.         0.        ]\n",
      "   [0.23921569 0.00392157 0.        ]\n",
      "   [0.23921569 0.00392157 0.00392157]\n",
      "   ...\n",
      "   [0.23529412 0.00784314 0.        ]\n",
      "   [0.23921569 0.00392157 0.        ]\n",
      "   [0.23921569 0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.00392157 0.00784314 0.        ]\n",
      "   ...\n",
      "   [0.00392157 0.00784314 0.        ]\n",
      "   [0.00392157 0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.00784314 0.00392157]\n",
      "   ...\n",
      "   [0.00392157 0.01176471 0.00392157]\n",
      "   [0.00392157 0.00784314 0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.00392157 0.        ]\n",
      "   ...\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.13333334 0.12156863 0.2901961 ]\n",
      "   [0.13440564 0.12156863 0.2901961 ]\n",
      "   [0.1364277  0.12156863 0.2901961 ]\n",
      "   ...\n",
      "   [0.         0.00392157 0.00784314]\n",
      "   [0.         0.00392157 0.00784314]\n",
      "   [0.         0.00392157 0.00784314]]\n",
      "\n",
      "  [[0.13463542 0.12026654 0.29149818]\n",
      "   [0.13535169 0.11991051 0.29114214]\n",
      "   [0.13670236 0.11923912 0.29047075]\n",
      "   ...\n",
      "   [0.         0.00419623 0.00784314]\n",
      "   [0.         0.00486761 0.00784314]\n",
      "   [0.         0.00522365 0.00784314]]\n",
      "\n",
      "  [[0.13681068 0.1180913  0.29367343]\n",
      "   [0.13693213 0.11714047 0.29272258]\n",
      "   [0.1371612  0.11534747 0.2909296 ]\n",
      "   ...\n",
      "   [0.         0.00465507 0.00784314]\n",
      "   [0.         0.00644806 0.00784314]\n",
      "   [0.         0.0073989  0.00784314]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.12807906 0.13377757 0.26096815]\n",
      "   [0.12807906 0.13472842 0.26084667]\n",
      "   [0.12807906 0.13652141 0.2606176 ]\n",
      "   ...\n",
      "   [0.         0.00436581 0.00784314]\n",
      "   [0.         0.00436581 0.00784314]\n",
      "   [0.         0.00436581 0.00784314]]\n",
      "\n",
      "  [[0.12155331 0.13595283 0.25226715]\n",
      "   [0.12155331 0.13630886 0.25155088]\n",
      "   [0.12155331 0.13698025 0.2502002 ]\n",
      "   ...\n",
      "   [0.         0.00654105 0.00784314]\n",
      "   [0.         0.00654105 0.00784314]\n",
      "   [0.         0.00654105 0.00784314]]\n",
      "\n",
      "  [[0.11764706 0.13725491 0.24705882]\n",
      "   [0.11764706 0.13725491 0.24598652]\n",
      "   [0.11764706 0.13725491 0.24396446]\n",
      "   ...\n",
      "   [0.         0.00784314 0.00784314]\n",
      "   [0.         0.00784314 0.00784314]\n",
      "   [0.         0.00784314 0.00784314]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.00784314 0.        ]\n",
      "   ...\n",
      "   [0.         0.00392157 0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.00392157 0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.00392157 0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.00784314 0.02352941 0.02352941]\n",
      "   [0.00784314 0.02751226 0.02751226]\n",
      "   [0.00784314 0.03066789 0.03066789]\n",
      "   ...\n",
      "   [0.00854779 0.02423407 0.02423407]\n",
      "   [0.00784314 0.02159926 0.02159926]\n",
      "   [0.00784314 0.01960784 0.01960784]]\n",
      "\n",
      "  [[0.01034007 0.02352941 0.02352941]\n",
      "   [0.0090721  0.02624428 0.02624428]\n",
      "   [0.00829181 0.02817096 0.02817096]\n",
      "   ...\n",
      "   [0.01014739 0.02628234 0.02628234]\n",
      "   [0.01034007 0.0240962  0.0240962 ]\n",
      "   [0.01034007 0.02210478 0.02210478]]\n",
      "\n",
      "  [[0.01021753 0.02352941 0.02352941]\n",
      "   [0.0082261  0.02630651 0.02630651]\n",
      "   [0.00700061 0.02857151 0.02857151]\n",
      "   ...\n",
      "   [0.01288524 0.02463463 0.02463463]\n",
      "   [0.01255038 0.02471098 0.02471098]\n",
      "   [0.01176471 0.02507659 0.02507659]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.00939032 0.01723346 0.01723346]\n",
      "   [0.00860464 0.02561921 0.02561921]\n",
      "   [0.0088258  0.03291291 0.03291291]\n",
      "   ...\n",
      "   [0.00756513 0.02507659 0.02507659]\n",
      "   [0.00860464 0.02700674 0.02700674]\n",
      "   [0.00939032 0.02899816 0.02899816]]\n",
      "\n",
      "  [[0.0106924  0.01711091 0.01711091]\n",
      "   [0.00996896 0.02345079 0.02345079]\n",
      "   [0.00971644 0.02959559 0.02959559]\n",
      "   ...\n",
      "   [0.00809913 0.02093614 0.02093614]\n",
      "   [0.00784314 0.0226103  0.0226103 ]\n",
      "   [0.00784314 0.02460172 0.02460172]]\n",
      "\n",
      "  [[0.01568628 0.01960784 0.01960784]\n",
      "   [0.01369485 0.01960784 0.01960784]\n",
      "   [0.01176471 0.01960784 0.01960784]\n",
      "   ...\n",
      "   [0.00854779 0.01639093 0.01639093]\n",
      "   [0.00784314 0.01761642 0.01761642]\n",
      "   [0.00784314 0.01960784 0.01960784]]]], shape=(16, 128, 128, 3), dtype=float32)\n",
      "\n",
      "tf.Tensor(\n",
      "[[[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]], shape=(16, 128, 128, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for a, b in trds.take(1):\n",
    "    print(a)\n",
    "    print()\n",
    "    print(b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dfb9469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img, mask in trds.take(3):\n",
    "#     plt.subplot(1,2,1)\n",
    "#     plt.imshow(img[0])\n",
    "#     plt.subplot(1,2,2)\n",
    "#     plt.imshow(mask[0,...,0], cmap='gray')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e42c5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_gate(x, g, inter_channels):\n",
    "    \"\"\"\n",
    "    Attention gate: x -> encoder feature (skip), g -> decoder gating signal.\n",
    "    Returns: x * attention_map (same shape as x).\n",
    "    \"\"\"\n",
    "    # 1x1 conv to reduce channels\n",
    "    theta_x = Conv2D(inter_channels, kernel_size=1, strides=1, padding='same')(x)\n",
    "    phi_g = Conv2D(inter_channels, kernel_size=1, strides=1, padding='same')(g)\n",
    "\n",
    "    add_xg = Add()([theta_x, phi_g])\n",
    "    act = ReLU()(add_xg)\n",
    "\n",
    "    psi = Conv2D(1, kernel_size=1, strides=1, padding='same')(act)\n",
    "    psi = Activation('sigmoid')(psi)   # attention coefficients in [0,1]\n",
    "\n",
    "    # broadcast multiply: attention map (H,W,1) * x (H,W,C)\n",
    "    attn_out = Multiply()([x, psi])\n",
    "    return attn_out\n",
    "\n",
    "\n",
    "def TumorSegNet_withAttention(input_shape=(256, 256, 3)):\n",
    "    inputs = Input(input_shape, name='Input_Layer')\n",
    "\n",
    "    # Encoder\n",
    "    c1 = Conv2D(64, 3, activation='relu', padding='same', name='Conv1_1')(inputs)\n",
    "    c1 = Conv2D(64, 3, activation='relu', padding='same', name='Conv1_2')(c1)\n",
    "    p1 = MaxPooling2D((2, 2), name='MaxPool1')(c1)\n",
    "\n",
    "    c2 = Conv2D(128, 3, activation='relu', padding='same', name='Conv2_1')(p1)\n",
    "    c2 = Conv2D(128, 3, activation='relu', padding='same', name='Conv2_2')(c2)\n",
    "    p2 = MaxPooling2D((2, 2), name='MaxPool2')(c2)\n",
    "\n",
    "    c3 = Conv2D(256, 3, activation='relu', padding='same', name='Conv3_1')(p2)\n",
    "    c3 = Conv2D(256, 3, activation='relu', padding='same', name='Conv3_2')(c3)\n",
    "    p3 = MaxPooling2D((2, 2), name='MaxPool3')(c3)\n",
    "\n",
    "    # Bottleneck\n",
    "    c4 = Conv2D(512, 3, activation='relu', padding='same', name='Bottleneck_Conv1')(p3)\n",
    "    c4 = Conv2D(512, 3, activation='relu', padding='same', name='Bottleneck_Conv2')(c4)\n",
    "    c4 = Dropout(0.5, name='Bottleneck_Dropout')(c4)\n",
    "\n",
    "    # Decoder - level 3 (connects to c3)\n",
    "    u3 = UpSampling2D((2, 2), name='UpSample3')(c4)\n",
    "    # attention gate for c3 using gating signal u3\n",
    "    att3 = attention_gate(c3, u3, inter_channels=128)  # inter_channels ~ half of skip channels\n",
    "    u3 = concatenate([u3, att3], name='Concat3')\n",
    "    c5 = Conv2D(256, 3, activation='relu', padding='same', name='Conv5_1')(u3)\n",
    "    c5 = Conv2D(256, 3, activation='relu', padding='same', name='Conv5_2')(c5)\n",
    "\n",
    "    # Decoder - level 2 (connects to c2)\n",
    "    u2 = UpSampling2D((2, 2), name='UpSample2')(c5)\n",
    "    att2 = attention_gate(c2, u2, inter_channels=64)\n",
    "    u2 = concatenate([u2, att2], name='Concat2')\n",
    "    c6 = Conv2D(128, 3, activation='relu', padding='same', name='Conv6_1')(u2)\n",
    "    c6 = Conv2D(128, 3, activation='relu', padding='same', name='Conv6_2')(c6)\n",
    "\n",
    "    # Decoder - level 1 (connects to c1)\n",
    "    u1 = UpSampling2D((2, 2), name='UpSample1')(c6)\n",
    "    att1 = attention_gate(c1, u1, inter_channels=32)\n",
    "    u1 = concatenate([u1, att1], name='Concat1')\n",
    "    c7 = Conv2D(64, 3, activation='relu', padding='same', name='Conv7_1')(u1)\n",
    "    c7 = Conv2D(64, 3, activation='relu', padding='same', name='Conv7_2')(c7)\n",
    "\n",
    "    outputs = Conv2D(1, 1, activation='sigmoid', name='Output_Layer')(c7)\n",
    "\n",
    "    return Model(inputs, outputs, name='TumorSegNet_Attention')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ba2e8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 6s/step - accuracy: 0.2134 - dice_coefficient: 0.0969 - loss: 0.8333 - val_accuracy: 0.8378 - val_dice_coefficient: 0.2222 - val_loss: 0.7393\n",
      "Epoch 2/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 6s/step - accuracy: 0.8077 - dice_coefficient: 0.2358 - loss: 0.7232 - val_accuracy: 0.9674 - val_dice_coefficient: 0.2052 - val_loss: 0.7299\n",
      "Epoch 3/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 6s/step - accuracy: 0.9230 - dice_coefficient: 0.3536 - loss: 0.6170 - val_accuracy: 0.9765 - val_dice_coefficient: 0.5033 - val_loss: 0.4771\n",
      "Epoch 4/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 6s/step - accuracy: 0.9571 - dice_coefficient: 0.5173 - loss: 0.4722 - val_accuracy: 0.9775 - val_dice_coefficient: 0.5419 - val_loss: 0.4401\n",
      "Epoch 5/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 6s/step - accuracy: 0.9632 - dice_coefficient: 0.5662 - loss: 0.4274 - val_accuracy: 0.9783 - val_dice_coefficient: 0.5877 - val_loss: 0.3973\n",
      "Epoch 6/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 6s/step - accuracy: 0.9637 - dice_coefficient: 0.6113 - loss: 0.3880 - val_accuracy: 0.9776 - val_dice_coefficient: 0.6007 - val_loss: 0.3876\n",
      "Epoch 7/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 6s/step - accuracy: 0.9622 - dice_coefficient: 0.6075 - loss: 0.3911 - val_accuracy: 0.9793 - val_dice_coefficient: 0.6419 - val_loss: 0.3539\n",
      "Epoch 8/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 6s/step - accuracy: 0.9672 - dice_coefficient: 0.6487 - loss: 0.3535 - val_accuracy: 0.9798 - val_dice_coefficient: 0.6374 - val_loss: 0.3539\n",
      "Epoch 9/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 6s/step - accuracy: 0.9692 - dice_coefficient: 0.6698 - loss: 0.3336 - val_accuracy: 0.9802 - val_dice_coefficient: 0.6485 - val_loss: 0.3447\n",
      "Epoch 10/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 6s/step - accuracy: 0.9700 - dice_coefficient: 0.6829 - loss: 0.3216 - val_accuracy: 0.9807 - val_dice_coefficient: 0.6591 - val_loss: 0.3346\n",
      "Epoch 11/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 6s/step - accuracy: 0.9705 - dice_coefficient: 0.6896 - loss: 0.3159 - val_accuracy: 0.9810 - val_dice_coefficient: 0.6617 - val_loss: 0.3316\n",
      "Epoch 12/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 6s/step - accuracy: 0.9705 - dice_coefficient: 0.6892 - loss: 0.3163 - val_accuracy: 0.9805 - val_dice_coefficient: 0.6123 - val_loss: 0.3707\n",
      "Epoch 13/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m386s\u001b[0m 6s/step - accuracy: 0.9716 - dice_coefficient: 0.7052 - loss: 0.3014 - val_accuracy: 0.9817 - val_dice_coefficient: 0.6760 - val_loss: 0.3177\n",
      "Epoch 14/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 6s/step - accuracy: 0.9723 - dice_coefficient: 0.7176 - loss: 0.2895 - val_accuracy: 0.9821 - val_dice_coefficient: 0.6726 - val_loss: 0.3221\n",
      "Epoch 15/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 6s/step - accuracy: 0.9728 - dice_coefficient: 0.7284 - loss: 0.2799 - val_accuracy: 0.9822 - val_dice_coefficient: 0.7117 - val_loss: 0.2950\n",
      "Epoch 16/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 6s/step - accuracy: 0.9731 - dice_coefficient: 0.7307 - loss: 0.2794 - val_accuracy: 0.9829 - val_dice_coefficient: 0.7193 - val_loss: 0.2815\n",
      "Epoch 17/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 6s/step - accuracy: 0.9742 - dice_coefficient: 0.7487 - loss: 0.2613 - val_accuracy: 0.9834 - val_dice_coefficient: 0.7425 - val_loss: 0.2680\n",
      "Epoch 18/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 7s/step - accuracy: 0.9748 - dice_coefficient: 0.7630 - loss: 0.2498 - val_accuracy: 0.9831 - val_dice_coefficient: 0.7312 - val_loss: 0.2721\n",
      "Epoch 19/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m444s\u001b[0m 7s/step - accuracy: 0.9746 - dice_coefficient: 0.7564 - loss: 0.2540 - val_accuracy: 0.9807 - val_dice_coefficient: 0.6073 - val_loss: 0.3700\n",
      "Epoch 20/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 7s/step - accuracy: 0.9735 - dice_coefficient: 0.7344 - loss: 0.2728 - val_accuracy: 0.9835 - val_dice_coefficient: 0.7151 - val_loss: 0.2846\n"
     ]
    }
   ],
   "source": [
    "# Instantiate and compile model\n",
    "model = TumorSegNet_withAttention(input_shape=(RESIZE, RESIZE, 3))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "            loss=CombinedSegmentationLoss(from_logits=False),\n",
    "            metrics=[dice_coefficient, 'accuracy'])\n",
    "\n",
    "# TensorBoard callback\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,\n",
    "    write_graph=True,\n",
    "    write_images=True,\n",
    "    update_freq='epoch',\n",
    "    profile_batch=0\n",
    ")\n",
    "\n",
    "# Custom callback to log sample predictions to TensorBoard\n",
    "class PredictionLogger(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, val_images, val_masks):\n",
    "        super(PredictionLogger, self).__init__()\n",
    "        self.val_images = val_images[:5]  # Log first 5 validation images\n",
    "        self.val_masks = val_masks[:5]\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        preds = self.model.predict(self.val_images)\n",
    "        preds = (preds > 0.5).astype(np.uint8)\n",
    "        \n",
    "        # Create figure with images, true masks, and predictions\n",
    "        fig = plt.figure(figsize=(15, 5 * len(self.val_images)))\n",
    "        for i in range(len(self.val_images)):\n",
    "            plt.subplot(len(self.val_images), 3, i * 3 + 1)\n",
    "            plt.imshow(self.val_images[i].squeeze(), cmap='gray')\n",
    "            plt.title('MRI Image')\n",
    "            plt.axis('off')\n",
    "            plt.subplot(len(self.val_images), 3, i * 3 + 2)\n",
    "            plt.imshow(self.val_masks[i].squeeze(), cmap='gray')\n",
    "            plt.title('True Mask')\n",
    "            plt.axis('off')\n",
    "            plt.subplot(len(self.val_images), 3, i * 3 + 3)\n",
    "            plt.imshow(preds[i].squeeze(), cmap='gray')\n",
    "            plt.title(f'Predicted Mask (Epoch {epoch + 1})')\n",
    "            plt.axis('off')\n",
    "        \n",
    "        # Log figure to TensorBoard\n",
    "        writer = tf.summary.create_file_writer(log_dir)\n",
    "        with writer.as_default():\n",
    "            tf.summary.image(\"Validation Predictions\", plot_to_image(fig), step=epoch)\n",
    "        plt.close(fig)\n",
    "\n",
    "# Convert matplotlib figure to TensorBoard image format\n",
    "def plot_to_image(figure):\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "# Other callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=5, restore_best_weights=True, monitor='val_dice_coefficient', mode='max'),\n",
    "    ModelCheckpoint('TumorSegNet_attbest.keras', save_best_only=True, monitor='val_dice_coefficient'),\n",
    "    tensorboard_callback,\n",
    "    # PredictionLogger(x_val['img'], masks_val)\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    trds,\n",
    "    validation_data=vlds,\n",
    "    epochs=20,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ee53d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('TumorSegNet_attention.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6e7ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
